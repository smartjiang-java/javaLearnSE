                                      Mysql实战45讲

## 1：一条sql查询语句是如何执行的？
![binaryTree](../mysql/image/1/sql查询步骤.png   "binaryTree")

mysql可以分为Server 层和存储引擎层两部分。
  Server 层涵盖mysql的大多数核心功能，以及所有的内置函数（如日期，时间，数学等），所有跨存储引擎的功能都在这一层实现，如存储过程，触发器，视图等。
  存储引擎负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的是InnoDB,mysql5.5开始默认存储引擎。 
所以，建表的时候不指定存储引擎，默认就是InnoDB,当然也可以在建表的时候进行指定存储引擎engine=memory,不同的存储引擎存取方式不同，支持的功能也不同。
不同的存储引擎共用一个Server 层。

Server 层
连接器：负责与客户端建立连接、获取权限、维持和管理链接。 可以在命令行里面输入账号和密码，但是在生产服务器不要直接跟密码，可能导致密码泄露。
      连接成功后，回到权限表里面查询你拥有的权限。一旦连接成功，即使用管理员账号对权限做修改，也不会影响已经存在连接的权限。只有再新建连接才会
      使用新的权限设置。连接成功后，如果没有后续动作，这个连接处于空闲状态。可以在show processlist看到，Command列显示为Sleep就是空闲连接。
      客户端如果太长时间没动静，连接器就会自动断开连接，时间由参数wait_timeout控制，默认值是8小时。一般建议使用长连接，因为建立连接的过程是很复杂的。
      问题：使用长连接后，mysql占用内存涨的比较快？
          这是因为mysql在执行过程中临时使用的内存是管理在连接对象里面的，这些资源会在连接断开的时候才释放。如果长时间累计，会被系统强行杀掉（oom）,
          也就是mysql异常重启。
      解决方法： 1：定期断开长连接。     2：mysql5.7之后的版本，在每次执行完一个比较大的操作后，通过执行mysql_reset_connection来重新初始化
               连接资源，这个过程不需要重连和重新权限验证，但是会将连接恢复到刚刚创建完成的状态。

查询缓存：mysql拿到一个查询请求后，会先查询缓存。之前执行过的sql语句及其结果会以key-valve的形式被直接缓存在内存中。
        但是我们大多数情况下都不建议使用缓存，因为对一个表的更新，这个表上所有的查询缓存都会清空，对于更新压力大的数据库来说，查询缓存的命中率会非常低。
        除非业务表很少更新，才适合使用缓存。mysql可以根据参数query_cache_type设置为demand,关闭缓存。对于确定使用缓存的sql，可以用SQL_CACHE
        指定，select SQL_CACHE * from T where ID=10;  mysql8.0之后移除了缓存。

分析器：对SQL语句进行解析，先做词法分析，识别字符串，识别表明和字段等等，再做语法分析，分析输入的sql语句是否满足mysql语法。
       如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，请关注use near之后的内容。

优化器：当表里面有多个索引的时候，决定使用那个索引；或者一个语句有多表关联join的时候，决定各个表的优化顺序。

执行器：执行sql语句，开始执行的时候，判断你对表是否有执行查询的权限；如果命中缓存，会在查询缓存返回结果的时候做权限验证。查询也会在优化器之前调用 precheck 验证权限
       如果有权限，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。执行完成后，结果写入查询缓存。
       问题：引擎扫描行数跟rows_examined是相同的吗？
            执行器调用一次，在引擎内部可能扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。在数据库的慢查询日志中看到一个 rows_examined 的字段，
            表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。


## 2：一条sql更新语句是如何执行的？
mysql的WAL技术:全称Write-Ahead Logging,关键点就是先写日志,再写磁盘.
 redo log:相当于小黑板,更新记录一般先写到redo log里,并更新内存,这时候更新操作就算完成了.InnoDB会在适当的时候,将操作记录更新到磁盘里面.
          redo log是固定大小的,写满了就必须要更新到磁盘一部分,ring buffer.从头开始写,写到末尾又回到开头循环写.
          有了redo log(InnoDB引擎特有的日志),InnoDB就可以保证即使数据发生异常重启,之前提交的记录都不会丢失,这个能力称为crash-safe.
          是物理日志,记录的是实际操作,循环写,空间固定会用完.是顺序写,并且可以组提交.满血复活
bin log: Server层也有自己的日志,称为binlog(归档日志).因为mysql一开始并没有InnoDB引擎,自带的是MiISAM.没有crash-safe能力,binlog日志
          只能用来归档,所有引擎都可以使用.是逻辑日志,记录的是语句的原始操作,追加写,binlog文件写到一定大小后会切换到下一个,并不会覆盖以前的日志.
          binlog有两种模式,statement格式记录sql预计,row格式记录行的内容,更新前和更新后,记录两条.
          binlog可关闭,set sql_log_bin=0关掉本线程的binlog日志.制造影分身
          
问题:redo写入的过程:两阶段提交,使得日志恢复的状态和数据库状态一致.
     1:查询到数据行,先加载到内存,完成更新操作后,调用引擎接口写入这行新数据.引擎将这行新数据更新到内存中,同时将这个更新操作记录
       到redo log中,此时redo log 处于prepare状态.然后告知执行器执行完成,随时可以提交事务.
     2:执行器生成这个操作的binlog,并把binlog写入磁盘
     3:执行器调用引擎的提交事务接口,引擎把刚刚写入的redo log改成提交(commit)状态,更新完成.

数据库的扩容:需要搭建一些备库开增加系统的读能力的时候,常采用全量备份+binlog实现.假如binlog数据不一致可能会导致主从数据不一致.


## 3: 事务隔离
ACID：原子性、一致性、隔离性、持久性。
当数据库有多个事务同事执行的时候，就可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就有了隔离级别的概念。隔离的越严实，效率就越低，安全性越高。

sql标准的事务隔离级别包括：读未提交、读已提交、可重复读和串行化。oracle默认读提交,mysql默认可重复读
读未提交(ru)：一个事务还没提交时，它做的变更就能被别的事务看到。没有视图的概念，直接返回记录上的最新值,带来脏读、不可重复度、幻读
读已提交（rc）：一个事务提交之后，它做的变更才会被其他事务看到。MVCC视图会在每一个SQL语句执行前创建一个，避免脏读，带来不可重复读和幻读
可重复读(rr)：一个事务在执行过程中，读取到的数据总是跟这个事务在启动时看到的数据是一致的。MVCC视图在开始事物的时候创建，整个事务存在期间都用这个事务，避免脏读和不可重复读，带来幻读
串行化(Serial)：对于同一行记录，读加共享锁，不允许写，写会加排他锁，不允许读写，当出现读写锁冲突的时候，后访问的事务必须等到前一个事务执行完成，才能继续执行。没有视图，通过锁实现数据访问，避免所有
解决幻读：使用间隙锁，mysql会为索引维护一套B+树，将索引分割成几个区间，比如（负无穷到10】,（10,30），【30到正无穷），操作10的时候，第一个区间与第二个区间加了间隙锁
 
transaction-isolation参数设置，通过 show variables like 'transaction-isolation'查看当前隔离级别 

事务隔离的实现：通过undo log和视图read-view实现事务隔离
在mysql中，实际上每条记录在更新的是狗都会同时记录一条回滚操作在 undo日志里。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。类似于git的版本迭代
同一个记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。

问题：回滚日志的删除？
     系统会判断，当没有事务再需要用到这些回滚日志时，就是系统里没有比这个回滚日志更早的read-view的时候，回滚日志会被删除。事务被提交后，undo log
     不会立即被删除，而是放入代清理的链表，由purge线程判断是否有其他事务使用undo段中上一个事务的版本信息。

问题：为什么不建议使用长事务？
    长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以在这个事务提交之前，数据库里面可能用到的回滚记录
    都必须保留，会导致大量占用存储空间。在mysql5.5之前的版本，回滚日志是跟随数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，
    文件也不会变小。另外，长事务还占用锁资源，也可能拖垮整个库。

问题：事务的启动方式：事务再 第一个select才启动
   1：显示启动事务语句，begin或者start transaction。配套的语句是commit,回滚语句是rollback
   2：set autocommit=0,这个命令会将线程的自动提交关闭掉，意味着你只执行了一个select语句，事务启动，但是并不会自动提交。知道你主动执行commit或者
     rollback语句，或者断开长连接。有些客户端框架会默认连接成功后执行一个set autocommit=0的操作，这就导致接下来的查询都在事务中，长连接导致了
     意外的长事务。因此，建议总是使用set autocommit=1,通过显式的方式来启动事务。减少交互次数，可以使用commit work and chain，少执行一个
     begin语句。
查询长事务： select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60


## 4:深入浅出索引上
索引的出现就是为了提高数据查询的效率，就像书的目录一样。mysql中，索引是在存储引擎层实现的。
索引的常见模型：哈希表、有序数组和搜索树。
哈希表+链表：类似于hashMap1.7,适用于等值查询的场景，在范围查询走全表查询，比如Memcached及一些其他的NoSQL引擎
有序数组：在等值查询和范围查询场景中的性能都非常优秀。在中间插入需要移动，成本太高。只适用于静态存储引擎。
搜索树：多使用N叉树，N取决于数据块的大小，不使用二叉树是为了减少访问多个数据块，减少寻址时间。mysql默认一个节点的长度是16K，一个整数字段索引的长度为8B,
      另外每个索引还跟着6B的指向其子树的指针，所以16K/14B =1170，接近1200数据块。树根的数据块总是在内存中，树的第二层也有很大概率在内存中。
LSM树:跳表，在redis中使用

InnoDB的索引模型：B+树，很好的配合磁盘的读写特征，减少单次查询的磁盘访问次数。
在InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用B+树模型，每一个索引在InnoDB里都是一颗B+树。
索引分成主键索引和非主键索引。
逐渐索引的叶子结点存的是页，页里面有多个整行数据，也就是数据块，在InnoDB里，主键uoyin也被称为聚簇索引。
非逐渐索引的叶子节点内容是页，页里面有多个主键的值，在InnoDB里，非主键索引也被称为二级索引。
使用主键查询，一般只需要一次;而使用非主键索引是先找到主键，再到主键索引里去搜索，这个过程称为回表。所以，我们应该尽量使用主键索引。如果我们不创建主键，
InnoDB会默认创建一个Rowid做主键

自增主键防止页分裂，逻辑删除并非物理删除防止页合并。
页分裂：数据所在数据页满了，需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂，影响性能和数据页的利用率。
页合并：相邻两个页由于删除了数据，利用率很低之后，会将数据页合并。
问题：有什么场景适合用业务字段直接做主键的？
     只有一个索引，而且改索引必须是唯一索引。

问题：重建索引k ,以及重建主键索引是否合理。
重建索引K是可以的，使得数据按顺序插入，页面的利用率变高，减少页分裂，省空间，合理。有些时候表的记录删除了，但是它的索引还在，并未释放。
```mysql
alter table T drop index k;
alter table T add index(k);
```
但是重建主键的过程不合理，不论是删除主键还是创建主键，都会将整个表重建。


## 5：深入浅出索引下
如何避免回表操作？
二级索引查询结果仅仅是主键，此时不需要回表查主键索引，称为覆盖索引。

联合索引：多个字段在一起建立索引。建立时考量复用能力。
B+树这种索引结构，可以利用索引的“最左原则”，来定位记录。这个最左前缀可以是联合索引的最左的N个字段，也可以是字符串索引的最左M个字符。
问题：既有联合索引，也有单独的索引，选择单独索引在小字段上。

索引下推：
mysql5.6之前先一个个回表，到主键索引上找出数据行，再对比字段值。
mysql5.6之后引入索引下推，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。


## 6:全局锁和表锁（server层实现）
数据库锁设计的初衷是处理并发问题。
根据枷锁的范围，mysql里面的锁大致可以分成全局锁、表级锁和行级锁。
全局锁：对整个数据库实例加锁。mysql加全局锁：Flush tables with read loch（FTWRL），让整个库处于只读状态。
   使用场景：做全库逻辑备份，也就是把整库每张表都select出来存成文本。不加锁备份的库不是一个逻辑时间点，数据不一致
   风险：主库做备份，在备份期间都不能执行更新，业务基本上就得停摆;从库上做备份，不能及时执行主库传来的binlog，导致主从延迟。
 除了加全局锁，还可以在可重复隔离级别下开启事务来备份。而且，这个过程中数据的增删改查不受影响。

问题: 可重复性隔离级别下开启事务备份和FTWRL区别？
    前者显然比后者好，但是为什么还需要后者？因为有的引擎不支持事务和可重复读这个隔离级别。比如MyISAM不支持事务，无法使用前者。
    官方自带的逻辑备份工具是mysqldump,使用参数-single-transaction开启事务，只适用于支持事务的引擎。这也是InnoDB代替MyISAM的原因。

问题：如果发现应用程序里有lock tables这样的语句，应该怎么办？
   1：要么是系统还在用MyISAM这类不支持事务的引擎，那么安排更换引擎
   2：如果引擎已经升级，代码还没升级。只需要把 lock tables 和 unlock tables改成begin和commit即可。

问题：对于FTWRL，全库只读，为什么不是用set global readonle=true的方式？
   1：在有些系统中，readonly的值被用来做其他逻辑，比如判断一个库是主库还是从库，修改这个值的影响面太大。
   2：FTWRL加锁，客户端发生异常断开，mysql会自动释放这个全局锁；而将整个库设为readonly后，发生异常，数据库会一直保持readonly状态，导致库长时间处于不可写状态，风险较高。

表级锁：增删改查（DML），修改表结构（DDL） mysql中表级别锁分两类，一种是表锁，一种是元数据锁（MDL）
 表锁的语法是 lock tables  ...read/write  ,可以用 unlock tables主动释放锁，也可以在客户端断开时自动释放。
   注意：如果线程A执行了 lock table t1 read,t2 write，那么只有A线程只可以读t1,读写t2.其他线程可以读t1,不可以读写t2，同时A线程也不能访问除t1、t2之外的表。
 元数据锁（MDL）：mysql5.5引入，不需要显示使用，在访问一个表的时候会被自动加上，保证读写的正确性。
   注意：对数据做CURD时加MDL读锁，其他线程可正常对表CURD，但是同一行数据更新会互斥，互斥的是行锁，不是MDL；对表结构做修改的时候，加MDL写锁，其他线程不能执行任何操作。
 
  问题：有时候给一个小表加字段，导致整个库挂了？
      MDL导致，在一个事务中，A线程先读取数据，加了MDL读锁；B线程进来，此时A线程没有执行完，A线程修改表结构，加MDL写锁；C线程进来，既不能读，也不能写。
      此时有查询比较频繁的语句，就会被阻塞，如果客户端有重试机制，重起线程进行访问，这个库的线程很快被塞满。

  问题：如何安全的给小表加字段？
      一般的，在alter table语句里面设置等待时间，等待时间内能拿到MDL写锁最好，拿不到也不阻塞后面的业，先放弃，之后载通过重试命令重复过程。
      MariaDB已经合并了AliSQL这个功能，目前这两个开源分支都支持下面的语句：
```mysql
alter table T nowait add columu...
alter table T wait N  add column...
```

问题：备份在备库上进行，用-single-transaction方法，另一边，在主库上对一个小表的字段做DDL,在备库会看到什么现象？
     备份的几个关键动作  Q1:开启事务   Q2:设置一个保存点  Q3:拿到表结构   Q4:正式导数据   Q5:回滚，释放DML锁
     对主库表修改的操作 在Q3之前来到：没有影响，备份拿到的是DDL之后的表结构
                     在Q3-Q4间来到：Q3拿到了表结构，Q4导数据时表结构被修改，报Table definition has changed, please retry transaction，现象：mysqldump 终止；
                     在Q4-Q5间来到：mysqldump沾着表的MDl读锁，binglog被阻塞  现象：主从延迟，直到Q5完成
                     在Q5之后来到：mysqldump释放了读锁，    现象：没有影响，备份拿到的是DDL之前的表


## 7：行锁
mysql的行锁是在引擎层由各个引擎自己实现的，并不是所有的引擎都支持行锁，MyISAM引擎就不支持行锁，意味着同一张表同一时刻只能有一个更新在执行。
innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。
在InnoDB中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。尽量将并发度高的行，放在事务的最后执行。

死锁：并发系统中不同线程出险循环资源依赖，设计的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
两种解决方法：
   1：直接进入等待，直至超时，这个超时时间是可以通过参数innodb_lock_wait_timeout来设置。默认50s,超时退出对于在线服务这个时间显然无法接受，但是设置的很小又无法判断是不是简单的锁等待
   2：发起死锁检测，发现死锁后，主动回滚链条中的某一个事务，让其他事务得以运行。将参数innodb_deadlock_detect设置为on,开启逻辑，这个是默认开启的
      不过这个是可以发现死锁并进行处理的，但是有额外负担，需要判断所在线程的依赖线程有没有被别人锁住，如此循环.如果有1000个并发线程,那么这个死锁
      检测操所就是100万级别的,虽然最终检测没有死锁,但是这期间要消耗大量的cpu资源，因此CPU利用率很高。

问题：活动，100个事务，CPU消耗近100%,mysql挂掉,如何解决（热点数据行更新导致的性能问题）？
    1：头痛医头的方法：如果确保业务一定不会死锁，可以临时把死锁检测关闭。但是存在风险，一旦死锁就会出现大量的超时。
    2：控制并发度。在代码端控制，做限流，对于同一行的操作不要来太多线程请求。这样死锁检测的工作量就不会很大
    3：拆行，一行拆多行，总和等于所有行记录的总值。每次操作时，可以随机选择行操作，降低冲突概率，减少锁等待个数，减少死锁检测的cpu消耗。
       但是对于减少操作，就需要判断一部分记录行变成0的情况，代码要特殊处理。


## 8：事务隔离还是不隔离的？


























